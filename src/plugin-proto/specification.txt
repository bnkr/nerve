TODO
----

* solve "sequences don't match stages" problem

The Pipeline
------------

The player is an ordered list of 'stages' which form a 'pipeline'.

The 'pipeline' is also the order of inter-stage communication of 'packets'.
'packets' are the data which is being processed.  'Events' are types of 'packet'
on the 'pipeline'.

Communication between 'stages' must respect the 'constant delay rule'.  This is
defined as such: given an single iteration of a 'pipeline' of one or more
'stages', no 'stage' must be visited twice.

[*note:* This is a tricky concept.  It is important when 'stages' can output
multiple 'packets' to perserve latency to the next 'stage'.  If the delay
changes then part of the 'pipeline' will starve for input.

For example, consider three connected 'stages' A, B, and C.  Each 'stage' copies
its input 'packet' twice.  A trivial 'packet' passing algorithm would buffer the
outputs from a 'stage' and then iterate them to call the next 'stage'.  This
results in stage A running once, then stage B running twice, and stage C four
times.  Now consider what would happen if each stage would produce variable
amounts of outputs.  The number of 'stage' operations from A to C becomes
variable.]

Input Stage
-----------

An 'input' is a kind of 'stage'.  The 'input' creates 'packets' from some kind
of I/O.  There is only ever one 'input' stage, and it must start the 'pipeline'.

The 'input' must handle several special 'events':

* +pause+ means stop reading
* +skip+ means move to a timestamp
* +load+ means load a new file
* +data+ means read more data

[*note:* This does not necessarily mean that the stage itself will query the
'packet' for event data.  It could be handled by the 'stage sequence' or the
'connections'.]

Simple Stage
------------

A 'simple stage' is a kind of 'stage' which deals with several 'events':

The 'simple stage' deals with the following 'events':

* +abandon+ means that the current work must be discarded because the context is
  changing (eg. song change).
* +flush+ means that no further work will appear (for now).  Any partially
  completed computation must be stopped and outputted (e.g playlist empty).
* +data+ is normal data to be processed.

The 'process' must propogate all these 'events' to the next 'stage' in the
'stage sequence' (i.e pass it down the 'pipeline').  [*note:* this would not
necessarily be done by a concrete stage object.]

Process Stage
-------------

A 'process' is an expansion of 'simple stage'.  'Process stages' always come
after the 'input' and before the 'output'.  The 'process' stage has a +data+
'event' whicn involves processing a single 'packet' and returning zero or more
'packets'.  A 'process stage' can delay, drop, create, re-order, or modify
'packets'.

Observer Stage
--------------

An 'observer' is an expansion of 'simple stage'.  It has an +observe+ 'event'
which involves reading a 'packet' but not modifying it.  'Observers' come after
the 'process stages'.

An 'observer' always propogates its 'packets' [*note*: this would not
necessarily be done by a concrete implementation of an 'observer'; the predicate
is intended to specify that there is no option to drop a 'packet'].

Output Stage
------------

An 'output' is an extension of an 'observer stage'.  The 'output' writes its
'packets' to some sound hardware (or similar).  There is only ever one 'output'
stage it is always after the 'processes'.

The 'output' including performs the same packet operations as a 'process'.
[*note:* This is necessary because an 'output' can be in the middle of a 'stage
sequence'.  If there is special handling for an 'output', then either each
'stage' will need to be checked by the 'stage sequence' or every 'stage' in the
sequence will need to check 'events' itself.  In other words, despite the
'output' doing what is essentially a noop, it actually works out being faster.
All that said, it does not necessarily mean that an actualy implementation of an
'output' needs the same concrete API as a 'process'; the "restriction" parts
(i.e no output modification) could be done in a shared place.]

[*note:* outputs often involve their own asynchronus queue (i.e the SDL thread)
which means the data would be shared with an observer.  This is OK because a)
observers don't modify and b), output data would need to be chunked anyway.]

The 'output' writes data to the 'input' to post 'events' which request more
data.  [*note:* this communication could involve a 'pipe' of 'local' or 'thread'
scope; therefore, it has the same constraints as a normal outputting of a
'packet', but it does not necessarily need to use an identical method.]

Stage Sequence
--------------

'Stages' are grouped into 'stage sequences'.  Each 'stage sequence' synchronises
several 'stages' in order of processing into one monothreaded group.

A 'stage sequence' which contains an 'input stage' is called the 'input
sequence'.  A 'stage sequence' which contains an 'output stage' is called the
'output sequence'.  'Stage sequences' which only contain 'process' or 'observer'
stages are known as 'process sequences' or 'observer sequences' respectively.
[*note:* It is easier to organise the sequences in these separate terms because
the operations on the different kinds of 'stage' are so different.]

Sequence Communication
----------------------

'Stage sequences' are 'connected' to each other in a 'connection'.  [*note:*
This is meant to facilitates 'stage' to 'stage' communication rather than imply
any special 'sequence' to 'sequence' communication.]  A 'connection' which reads
data in is an 'input connection' while one which writes data out is an 'output
connection'.  A 'connection' works by using 'pipes'.  A 'pipe' which operates
between two threads is a 'thread pipe' while one that only operates within a
thread is a 'local pipe'.  [*note:* Since a 'stage sequence' is mono threaded,
all communication between 'stages' within a 'stage sequence' will be done with a
'local pipe'.]

The 'input connection' to first 'sequence' in the 'pipeline' and the output
'connection' after the final 'observer' are called 'terminators'; the 'initial
terminator' and 'final terminator' respectively.

All 'output connections' except the 'final terminator' always use 'thread
pipes'.  All 'input connections' except the 'initial terminator' use 'thread
pipes'.  The 'initial terminator' can use a 'local pipe' if the 'input' and
'output' 'stages' are both in the same 'job'.  [*note:* Using 'thread pipes' for
every 'stage sequence' means that if the 'input' and 'output' are in the same
thread, only one of them blocks (the 'output') but otherwise they both block due
to normal 'pipe' smenatics.]

In communications between 'stage sequences' and between 'stages', there must
always be exactly one 'packet operation' (the work done to process each 'event')
per visit to each 'stage' in the 'pipeline's' sequence.  There must never be a
variable number of 'packet operations' between two ordered 'stages'. This is
called  the 'constant delay rule'.  [*note:* Using 'thread pipes' between 'stage
sequences' automatically ensures this rule, assuming the mono-threaded parts
also respect it.]

[*note:* The 'constant delay rule' is a tricky concept.  It means is that
multiple 'packet' output must be handled without blocking; there is never more
than one 'packet' at a time passed to a single 'stage'.  To put it another way,
we immediately pass the first 'packet' of output from a 'stage' on to the next
'stage' in 'pipeline' order regardless of how many total 'packets' were
generated.  We can not handle multiple 'packets' by repeatedly calling the next
'stage' in a loop over those 'packets' because we end up with a long delay in
writing any 'packets' to a 'thread pipe'.  This means that any waiting threads
will will starve.]

Jobs
----

'Stage sequences' are contained in 'jobs'.  Each 'job' represents a single
thread.  A 'job' can contain multiple 'stage sequences'. [*note:* Thus, a job
can block multiple times.

Problems
--------

.extra input buffer operations
- in a stage sequence which is not the start terminator, we only read a single
  packet
- the current API design requires that add this single packet to a buffer before
  processing.

.sequences don't match stages
* the current stage sequence is massively over the top for observers which never
  actually modify anything or output multiple packets
* we could add an +observer_stage_sequence+
  - this could also contain the 'output stage' which could fix the API mess in
    there
* in order to preserve "any stage in any thread", this means relaxing the
  requirements on non-terminating stage sequences outputting to thread pipes.
* that would break the constant delay rule
* unless we did another progressive buffering step in the job thread
* we have a similar problem though, because a hypothetical observer stage
  sequence wouldn't ever need progressive buffering (it only outputs one stage).
* it is the stage sequence implementation itself which is at fault at the moment
  because it works in a loop of "while there is data buffered".
