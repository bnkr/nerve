TODO
----

* see "problems"

The Pipeline
------------

The player is an ordered list of 'stages' which form a 'pipeline'.

The 'pipeline' is also the order of inter-stage communication of 'packets'.
'packets' are the data which is being processed.  'Events' are types of 'packet'
on the 'pipeline'.

Communication between 'stages' must respect the 'constant delay rule'.  This is
defined as such: given an single iteration of a 'pipeline' of one or more
'stages', no 'stage' must be visited twice.

[*note:* This is a tricky concept.  It is important when 'stages' can output
multiple 'packets' to perserve latency to the next 'stage'.  If the delay
changes then part of the 'pipeline' will starve for input.

For example, consider three connected 'stages' A, B, and C.  Each 'stage' copies
its input 'packet' twice.  A trivial 'packet' passing algorithm would buffer the
outputs from a 'stage' and then iterate them to call the next 'stage'.  This
results in stage A running once, then stage B running twice, and stage C four
times.  Now consider what would happen if each stage would produce variable
amounts of outputs.  The number of 'stage' operations from A to C becomes
variable.]

Input Stage
-----------

An 'input' is a kind of 'stage'.  The 'input' creates 'packets' from some kind
of I/O.  There is only ever one 'input' stage, and it must start the 'pipeline'.

The 'input' must handle several special 'events':

* +pause+ means stop reading
* +skip+ means move to a timestamp
* +load+ means load a new file
* +data+ means read more data

[*note:* This does not necessarily mean that the stage itself will query the
'packet' for event data.  It could be handled by the 'stage sequence' or the
'connections'.]

Simple Stage
------------

A 'simple stage' is a kind of 'stage' which deals with several 'events':

The 'simple stage' deals with the following 'events':

* +abandon+ means that the current work must be discarded because the context is
  changing (eg. song change).
* +flush+ means that no further work will appear (for now).  Any partially
  completed computation must be stopped and outputted (e.g playlist empty).
* +data+ is normal data to be processed.

The 'process' must propogate all these 'events' to the next 'stage' in the
'stage sequence' (i.e pass it down the 'pipeline').  [*note:* this would not
necessarily be done by a concrete stage object.]

Process Stage
-------------

A 'process' is an expansion of 'simple stage'.  'Process stages' always come
after the 'input' and before the 'output'.  The 'process' stage has a +data+
'event' whicn involves processing a single 'packet' and returning zero or more
'packets'.  A 'process stage' can delay, drop, create, re-order, or modify
'packets'.

Observer Stage
--------------

An 'observer' is an expansion of 'simple stage'.  It has an +observe+ 'event'
which involves reading a 'packet' but not modifying it.  'Observers' come after
the 'process stages'.

An 'observer' always propogates its 'packets' [*note*: this would not
necessarily be done by a concrete implementation of an 'observer'; the predicate
is intended to specify that there is no option to drop a 'packet'].

Output Stage
------------

An 'output' is an extension of an 'observer stage'.  The 'output' writes its
'packets' to some sound hardware (or similar).  There is only ever one 'output'
stage it is always after the 'processes'.

The 'output' including performs the same packet operations as a 'process'.
[*note:* This is necessary because an 'output' can be in the middle of a 'stage
sequence'.  If there is special handling for an 'output', then either each
'stage' will need to be checked by the 'stage sequence' or every 'stage' in the
sequence will need to check 'events' itself.  In other words, despite the
'output' doing what is essentially a noop, it actually works out being faster.
All that said, it does not necessarily mean that an actualy implementation of an
'output' needs the same concrete API as a 'process'; the "restriction" parts
(i.e no output modification) could be done in a shared place.]

[*note:* outputs often involve their own asynchronus queue (i.e the SDL thread)
which means the data would be shared with an observer.  This is OK because a)
observers don't modify and b), output data would need to be chunked anyway.]

The 'output' writes data to the 'input' to post 'events' which request more
data.  [*note:* this communication could involve a 'pipe' of 'local' or 'thread'
scope; therefore, it has the same constraints as a normal outputting of a
'packet', but it does not necessarily need to use an identical method.]

Stage Sequence
--------------

'Stages' are grouped into 'stage sequences'.  Each 'stage sequence' synchronises
several 'stages' in order of processing into one monothreaded group.

A 'stage sequence' which contains an 'input stage' is called the 'input
sequence'.  A 'stage sequence' which contains an 'output stage' is called the
'output sequence'.  'Stage sequences' which only contain 'process' or 'observer'
stages are known as 'process sequences' or 'observer sequences' respectively.
[*note:* It is easier to organise the sequences in these separate terms because
the operations on the different kinds of 'stage' are so different.]

Sequence Communication
----------------------

'Stage sequences' are 'connected' to each other in a 'connection'.  [*note:*
This is meant to facilitates 'stage' to 'stage' communication rather than imply
any special 'sequence' to 'sequence' communication.]  A 'connection' which reads
data in is an 'input connection' while one which writes data out is an 'output
connection'.  A 'connection' works by using 'pipes'.  A 'pipe' which operates
between two threads is a 'thread pipe' while one that only operates within a
thread is a 'local pipe'.  [*note:* Since a 'stage sequence' is mono threaded,
all communication between 'stages' within a 'stage sequence' will be done with a
'local pipe'.]

The 'input connection' to first 'sequence' in the 'pipeline' and the output
'connection' after the final 'observer' are called 'terminators'; the 'initial
terminator' and 'final terminator' respectively.

All 'output connections' except the 'final terminator' always use 'thread
pipes'.  All 'input connections' except the 'initial terminator' use 'thread
pipes'.  The 'initial terminator' can use a 'local pipe' if the 'input' and
'output' 'stages' are both in the same 'job'.  [*note:* Using 'thread pipes' for
every 'stage sequence' means that if the 'input' and 'output' are in the same
thread, only one of them blocks (the 'output') but otherwise they both block due
to normal 'pipe' smenatics.  'Thread pipes' also trivially enforce the 'constant
delay rule' between connected 'stages'.]

Jobs
----

'Stage sequences' are contained in 'jobs'.  Each 'job' represents a single
thread.  A 'job' can contain multiple 'stage sequences'. [*note:* Thus, a job
can block multiple times.]

'Jobs' must not starve any 'stage sequence'.  [*note:* This is more nuanced than
it first appears, hence explicit specification of something which is really
impled.  Consider 'stage sequences' A, B, and C which are 'connected'.  The the
same 'job' but B is not.  'job' implementation waits for data on each 'sequence'
it sees.  A and C are in If A outputs a 'packet' and B consumes that 'packet',
then C will starve while A should have run again.  This happens regardless of
constant delay.]

Problems
--------

.sequences don't match stages

* any constant-delay sequence implementation which handles the producer stage is
  going to be over the top for observer stages because they never output things
* it would be easier to specify a single stage type per sequence and multiple
  directly connected sequences per job
* the current specification of sequences using thread pipes means that we can't
  have multiple connected sequences in a job.

* the actual implementation of mono-stage sequences is pretty easy because they
  are really just less complicated specialisations of the existing general
  sequence

.sequence starvation

* the specification of "no srarvation" is silly because "no stavation" is
  implied.
* what we should really specify is a consracint which prevents starvation, such
  as only blocking once.
* "only block once" is contradicted by having multiple multiple thread pipes,
  which is required by multiple non-connrected sequences per job (which is a
  hard requirement)
